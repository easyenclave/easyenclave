# Builtin Deploy Examples (GCP)
#
# Canonical GCP example workflow:
# - hello-tdx on tiny
# - private-llm on llm (OpenAI-compatible smoke test)

name: Builtin Deploy Examples (GCP)

on:
  workflow_call:
    inputs:
      cp_url:
        required: false
        type: string
        default: "https://app.easyenclave.com"
      cp_expected_git_sha:
        required: false
        type: string
        default: ""
      source_ref:
        required: false
        type: string
        default: ""
      hello_tdx_image:
        required: false
        type: string
        default: ""
      private_llm_ollama_image:
        required: false
        type: string
        default: ""
      private_llm_model_loader_image:
        required: false
        type: string
        default: ""
  workflow_dispatch:
    inputs:
      cp_url:
        description: "Control plane URL"
        required: false
        default: "https://app.easyenclave.com"
      cp_expected_git_sha:
        description: "Expected control-plane git SHA from /health (optional)"
        required: false
        default: ""
      source_ref:
        description: "Git ref to checkout"
        required: false
        default: ""
      hello_tdx_image:
        description: "Optional hello-tdx image override (digest ref)"
        required: false
        default: ""
      private_llm_ollama_image:
        description: "Optional private-llm ollama image override (digest ref)"
        required: false
        default: ""
      private_llm_model_loader_image:
        description: "Optional private-llm model-loader image override (digest ref)"
        required: false
        default: ""

concurrency:
  # Keep one GCP deploy-example run at a time; allow baremetal/default workflow to run in parallel.
  group: easyenclave-deploy-examples-gcp-${{ github.run_id }}
  # Prefer the newest run; older deploy-example runs can get stuck on slow capacity.
  cancel-in-progress: true

env:
  CP_URL: ${{ inputs.cp_url || github.event.inputs.cp_url || 'https://app.easyenclave.com' }}
  CP_EXPECTED_GIT_SHA: ${{ inputs.cp_expected_git_sha || github.event.inputs.cp_expected_git_sha || '' }}
  HELLO_TDX_IMAGE: ${{ inputs.hello_tdx_image || github.event.inputs.hello_tdx_image || '' }}
  PRIVATE_LLM_OLLAMA_IMAGE: ${{ inputs.private_llm_ollama_image || github.event.inputs.private_llm_ollama_image || '' }}
  PRIVATE_LLM_MODEL_LOADER_IMAGE: ${{ inputs.private_llm_model_loader_image || github.event.inputs.private_llm_model_loader_image || '' }}

jobs:
  deploy-hello-tdx-gcp:
    name: Deploy Hello TDX (gcp)
    runs-on: [self-hosted, tdx]
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.source_ref || github.event.inputs.source_ref || github.sha }}

      - name: Prepare hello-tdx compose (optional release image override)
        id: hello_compose
        shell: bash
        run: |
          set -euo pipefail
          src="examples/hello-tdx/docker-compose.yml"
          out="${RUNNER_TEMP}/hello-tdx.compose.yml"
          cp "$src" "$out"
          if [ -n "${HELLO_TDX_IMAGE:-}" ]; then
            if ! grep -qE 'image:[[:space:]]*hashicorp/http-echo:latest' "$out"; then
              echo "::error::Expected hello-tdx image line not found in $src"
              exit 1
            fi
            escaped="$(printf '%s' "${HELLO_TDX_IMAGE}" | sed -e 's/[&|]/\\&/g')"
            sed -i -E "s|image:[[:space:]]*hashicorp/http-echo:latest|image: ${escaped}|g" "$out"
          fi
          echo "compose_file=$out" >> "$GITHUB_OUTPUT"

      - name: Wait for control plane bootstrap (git_sha match)
        shell: bash
        run: |
          set -euo pipefail
          echo "Waiting for $CP_URL/health git_sha=$CP_EXPECTED_GIT_SHA"
          deadline=$(( $(date +%s) + 900 ))
          while :; do
            body="$(curl -fsS "$CP_URL/health" 2>/dev/null || true)"
            if [ -z "${CP_EXPECTED_GIT_SHA:-}" ]; then
              if [ -n "${body:-}" ]; then
                echo "Control plane ready (git_sha check skipped)"
                break
              fi
            fi
            sha="$(echo "${body:-}" | jq -r '.git_sha // empty' 2>/dev/null || true)"
            if [ -n "${sha:-}" ] && [ "$sha" = "$CP_EXPECTED_GIT_SHA" ]; then
              echo "Control plane ready: git_sha=$sha"
              break
            fi
            now="$(date +%s)"
            if [ "$now" -ge "$deadline" ]; then
              echo "::error::Timed out waiting for control plane git_sha=$CP_EXPECTED_GIT_SHA"
              echo "Last /health:"
              echo "${body:-<empty>}"
              exit 1
            fi
            sleep 5
          done

      - name: Validate required secrets for GCP deploy
        id: cfg_hello
        shell: bash
        env:
          AGENT_ADMIN_PASSWORD: ${{ secrets.AGENT_ADMIN_PASSWORD }}
          CP_ADMIN_PASSWORD: ${{ secrets.CP_ADMIN_PASSWORD }}
        run: |
          set -euo pipefail
          missing=0
          for v in AGENT_ADMIN_PASSWORD CP_ADMIN_PASSWORD; do
            if [ -z "${!v:-}" ]; then
              echo "::warning::Missing secret: $v"
              missing=1
            fi
          done
          if [ "$missing" -ne 0 ]; then
            echo "configured=false" >> "$GITHUB_OUTPUT"
            echo "::notice::GCP hello deploy is not configured; skipping job actions."
            exit 0
          fi
          echo "configured=true" >> "$GITHUB_OUTPUT"

      - name: Ensure app exists (idempotent)
        if: steps.cfg_hello.outputs.configured == 'true'
        uses: ./.github/actions/register-app
        with:
          name: hello-tdx
          description: "Hello TDX - Example app demonstrating TDX attestation"
          control_plane_url: ${{ env.CP_URL }}

      - name: Deploy to EasyEnclave (GCP)
        if: steps.cfg_hello.outputs.configured == 'true'
        uses: ./.github/actions/gcp-deploy-example
        with:
          app_name: hello-tdx
          compose_file: ${{ steps.hello_compose.outputs.compose_file }}
          service_name: hello-tdx
          health_endpoint: /
          control_plane_url: ${{ env.CP_URL }}
          agent_admin_password: ${{ secrets.AGENT_ADMIN_PASSWORD }}
          github_owner: ${{ github.repository_owner }}
          node_size: tiny
          gcp_datacenter: ${{ vars.GCP_DATACENTER || 'gcp:us-central1-a' }}
          billing_account_id: ${{ secrets.CP_DEPLOYER_ACCOUNT_ID }}
          billing_api_key: ${{ secrets.CP_DEPLOYER_API_KEY }}
          billing_months: "1"
          gcp_zone: ${{ vars.GCP_ZONE || 'us-central1-a,us-central1-b,us-central1-c,us-central1-f,us-east4-a,us-west1-b' }}
          cp_admin_token: ${{ secrets.CP_ADMIN_TOKEN }}
          cp_admin_password: ${{ secrets.CP_ADMIN_PASSWORD }}

  deploy-private-llm-gcp:
    name: Deploy Private LLM (gcp)
    runs-on: [self-hosted, tdx]
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ inputs.source_ref || github.event.inputs.source_ref || github.sha }}

      - name: Prepare private-llm compose (optional release image overrides)
        id: llm_compose
        shell: bash
        run: |
          set -euo pipefail
          src="examples/private-llm/docker-compose.yml"
          out="${RUNNER_TEMP}/private-llm.compose.yml"
          cp "$src" "$out"

          if [ -n "${PRIVATE_LLM_OLLAMA_IMAGE:-}" ]; then
            if ! grep -qE 'image:[[:space:]]*ollama/ollama:latest' "$out"; then
              echo "::error::Expected private-llm ollama image line not found in $src"
              exit 1
            fi
            escaped="$(printf '%s' "${PRIVATE_LLM_OLLAMA_IMAGE}" | sed -e 's/[&|]/\\&/g')"
            sed -i -E "s|image:[[:space:]]*ollama/ollama:latest|image: ${escaped}|g" "$out"
          fi

          if [ -n "${PRIVATE_LLM_MODEL_LOADER_IMAGE:-}" ]; then
            if ! grep -qE 'image:[[:space:]]*curlimages/curl:latest' "$out"; then
              echo "::error::Expected private-llm model-loader image line not found in $src"
              exit 1
            fi
            escaped="$(printf '%s' "${PRIVATE_LLM_MODEL_LOADER_IMAGE}" | sed -e 's/[&|]/\\&/g')"
            sed -i -E "s|image:[[:space:]]*curlimages/curl:latest|image: ${escaped}|g" "$out"
          fi

          echo "compose_file=$out" >> "$GITHUB_OUTPUT"

      - name: Wait for control plane bootstrap (git_sha match)
        shell: bash
        run: |
          set -euo pipefail
          echo "Waiting for $CP_URL/health git_sha=$CP_EXPECTED_GIT_SHA"
          deadline=$(( $(date +%s) + 900 ))
          while :; do
            body="$(curl -fsS "$CP_URL/health" 2>/dev/null || true)"
            if [ -z "${CP_EXPECTED_GIT_SHA:-}" ]; then
              if [ -n "${body:-}" ]; then
                echo "Control plane ready (git_sha check skipped)"
                break
              fi
            fi
            sha="$(echo "${body:-}" | jq -r '.git_sha // empty' 2>/dev/null || true)"
            if [ -n "${sha:-}" ] && [ "$sha" = "$CP_EXPECTED_GIT_SHA" ]; then
              echo "Control plane ready: git_sha=$sha"
              break
            fi
            now="$(date +%s)"
            if [ "$now" -ge "$deadline" ]; then
              echo "::error::Timed out waiting for control plane git_sha=$CP_EXPECTED_GIT_SHA"
              echo "Last /health:"
              echo "${body:-<empty>}"
              exit 1
            fi
            sleep 5
          done

      - name: Validate required secrets for GCP LLM deploy
        id: cfg_llm
        shell: bash
        env:
          # Agent admin password (set on deployed nodes for local admin UI auth).
          AGENT_ADMIN_PASSWORD: ${{ secrets.AGENT_ADMIN_PASSWORD }}
          # Control-plane admin auth (used for trusted MRTD writes / cleanup APIs).
          CP_ADMIN_TOKEN: ${{ secrets.CP_ADMIN_TOKEN }}
          CP_ADMIN_PASSWORD: ${{ secrets.CP_ADMIN_PASSWORD }}
        run: |
          set -euo pipefail
          missing=0
          for v in AGENT_ADMIN_PASSWORD CP_ADMIN_PASSWORD; do
            if [ -z "${!v:-}" ]; then
              echo "::warning::Missing secret: $v"
              missing=1
            fi
          done
          if [ "$missing" -ne 0 ]; then
            echo "configured=false" >> "$GITHUB_OUTPUT"
            echo "::notice::GCP private-llm deploy is not configured; skipping job actions."
            exit 0
          fi
          echo "configured=true" >> "$GITHUB_OUTPUT"

      - name: Resolve GCP datacenter target (llm)
        if: steps.cfg_llm.outputs.configured == 'true'
        id: target
        shell: bash
        run: |
          set -euo pipefail
          dc="$(echo "${{ vars.GCP_DATACENTER || '' }}" | tr '[:upper:]' '[:lower:]' | xargs)"
          if [ -z "$dc" ]; then
            dc="gcp:us-central1-a"
          fi
          case "$dc" in
            gcp:*) ;;
            gcp) ;;
            *) dc="gcp:${dc}" ;;
          esac
          echo "datacenter=$dc" >> "$GITHUB_OUTPUT"
          echo "Resolved datacenter: $dc"

      - name: Ensure GCP llm capacity for private-llm
        if: steps.cfg_llm.outputs.configured == 'true'
        id: preflight_llm
        uses: ./.github/actions/preflight-gcp
        with:
          control_plane_url: ${{ env.CP_URL }}
          node_size: llm
          wait_seconds: "1800"
          billing_account_id: ${{ secrets.CP_DEPLOYER_ACCOUNT_ID }}
          billing_api_key: ${{ secrets.CP_DEPLOYER_API_KEY }}
          billing_months: "1"
          gcp_datacenter: ${{ steps.target.outputs.datacenter }}
          gcp_project_id: ${{ secrets.GCP_PROJECT_ID }}
          gcp_service_account_key: ${{ secrets.GCP_SERVICE_ACCOUNT_KEY }}
          gcp_zone: ${{ vars.GCP_ZONE || 'us-central1-a,us-central1-b,us-central1-c,us-central1-f,us-east4-a,us-west1-b' }}
          cp_admin_token: ${{ secrets.CP_ADMIN_TOKEN }}
          cp_admin_password: ${{ secrets.CP_ADMIN_PASSWORD }}

      - name: Ensure app exists (idempotent)
        if: steps.cfg_llm.outputs.configured == 'true'
        uses: ./.github/actions/register-app
        with:
          name: private-llm
          description: "Private LLM - Ollama running in a TDX enclave"
          control_plane_url: ${{ env.CP_URL }}

      - name: Deploy to EasyEnclave (GCP)
        if: steps.cfg_llm.outputs.configured == 'true'
        id: deploy
        uses: ./.github/actions/gcp-deploy-example
        with:
          app_name: private-llm
          compose_file: ${{ steps.llm_compose.outputs.compose_file }}
          service_name: private-llm
          health_endpoint: /
          control_plane_url: ${{ env.CP_URL }}
          agent_admin_password: ${{ secrets.AGENT_ADMIN_PASSWORD }}
          github_owner: ${{ github.repository_owner }}
          node_size: llm
          gcp_datacenter: ${{ vars.GCP_DATACENTER || 'gcp:us-central1-a' }}
          billing_account_id: ${{ secrets.CP_DEPLOYER_ACCOUNT_ID }}
          billing_api_key: ${{ secrets.CP_DEPLOYER_API_KEY }}
          billing_months: "1"
          gcp_zone: ${{ vars.GCP_ZONE || 'us-central1-a,us-central1-b,us-central1-c,us-central1-f,us-east4-a,us-west1-b' }}
          cp_admin_token: ${{ secrets.CP_ADMIN_TOKEN }}
          cp_admin_password: ${{ secrets.CP_ADMIN_PASSWORD }}

      - name: Set up Python
        if: steps.cfg_llm.outputs.configured == 'true'
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install SDK and OpenAI client
        if: steps.cfg_llm.outputs.configured == 'true'
        run: pip install ./sdk/ openai

      - name: Smoke test private-llm (OpenAI-compatible)
        if: steps.cfg_llm.outputs.configured == 'true'
        env:
          SERVICE_URL: ${{ steps.deploy.outputs.service_url }}
          EASYENCLAVE_URL: ${{ env.CP_URL }}
        shell: bash
        run: |
          set -euo pipefail
          python3 - <<'PY'
          import os
          import time

          import httpx
          import httpx as _httpx
          from easyenclave import EasyEnclaveClient
          from openai import OpenAI

          MODEL = "smollm2:135m"
          CHAT_PATH = "/v1/chat/completions"
          CHAT_BODY = {
              "model": MODEL,
              "messages": [{"role": "user", "content": "Say hello in one sentence."}],
          }
          TIMEOUT = 300
          RETRY_INTERVAL = 15

          service_url = os.environ["SERVICE_URL"].rstrip("/")
          easyenclave_url = os.environ["EASYENCLAVE_URL"].rstrip("/")

          def wait_ready(label, fn):
              deadline = time.monotonic() + TIMEOUT
              last_error = RuntimeError("unknown")
              while True:
                  try:
                      content = fn()
                      if content and content != "null":
                          print(f"[{label}] OK: {content}")
                          return
                  except Exception as exc:
                      last_error = exc
                  if time.monotonic() >= deadline:
                      raise RuntimeError(
                          f"[{label}] FAIL: not ready after {TIMEOUT}s â€” {last_error}"
                      )
                  print(f"[{label}] Model not ready, retrying in {RETRY_INTERVAL}s...")
                  time.sleep(RETRY_INTERVAL)

          def extract_content(resp: httpx.Response) -> str:
              data = resp.json()
              return data["choices"][0]["message"]["content"]

          def direct_call():
              url = f"{service_url}{CHAT_PATH}"
              with httpx.Client(timeout=60, headers={"user-agent": "EasyEnclave-Test/1.0"}) as c:
                  resp = c.post(url, json=CHAT_BODY)
                  resp.raise_for_status()
                  return extract_content(resp)

          ee = EasyEnclaveClient(easyenclave_url, verify=False)
          llm = ee.service("private-llm")

          def proxy_call():
              resp = llm.post(CHAT_PATH, json=CHAT_BODY, timeout=60)
              resp.raise_for_status()
              return extract_content(resp)

          def _strip_bot_headers(req: _httpx.Request):
              req.headers["user-agent"] = "EasyEnclave-Test/1.0"
              for key in [k for k in req.headers if k.lower().startswith("x-stainless-")]:
                  del req.headers[key]

          openai_client = OpenAI(
              base_url=f"{llm.base_url.rstrip('/')}/v1",
              api_key="unused",
              http_client=_httpx.Client(
                  verify=False,
                  event_hooks={"request": [_strip_bot_headers]},
              ),
          )

          def openai_call():
              completion = openai_client.chat.completions.create(
                  model=MODEL,
                  messages=[{"role": "user", "content": "Say hello in one sentence."}],
                  timeout=60,
              )
              return completion.choices[0].message.content or ""

          wait_ready("direct", direct_call)
          wait_ready("proxy", proxy_call)
          wait_ready("openai", openai_call)
          PY

      - name: Resolve admin token for LLM teardown
        id: teardown_auth
        if: always() && steps.cfg_llm.outputs.configured == 'true' && steps.deploy.outcome == 'success'
        shell: bash
        env:
          CP_ADMIN_TOKEN: ${{ secrets.CP_ADMIN_TOKEN }}
          CP_ADMIN_PASSWORD: ${{ secrets.CP_ADMIN_PASSWORD }}
        run: |
          set -euo pipefail
          token="$(echo "${CP_ADMIN_TOKEN:-}" | xargs)"
          if [ -z "$token" ] && [ -n "${CP_ADMIN_PASSWORD:-}" ]; then
            payload="$(jq -cn --arg p "${CP_ADMIN_PASSWORD}" '{password: $p}')"
            token="$(curl -sS -X POST "$CP_URL/admin/login" -H 'Content-Type: application/json' -d "$payload" | jq -r '.token // empty' 2>/dev/null || true)"
          fi
          if [ -z "$token" ]; then
            echo "::error::Could not resolve admin token for teardown (set CP_ADMIN_TOKEN or CP_ADMIN_PASSWORD)."
            exit 1
          fi
          echo "::add-mask::$token"
          echo "admin_token=$token" >> "$GITHUB_OUTPUT"
          echo "Resolved admin token for teardown."

      - name: Teardown private-llm GCP deployment and capacity
        if: always() && steps.cfg_llm.outputs.configured == 'true' && steps.deploy.outcome == 'success'
        shell: bash
        env:
          ADMIN_TOKEN: ${{ steps.teardown_auth.outputs.admin_token }}
          AGENT_ID: ${{ steps.deploy.outputs.agent_id }}
          GCP_DC: ${{ steps.target.outputs.datacenter }}
        run: |
          set -euo pipefail
          if [ -z "${AGENT_ID:-}" ]; then
            echo "::warning::No deployed agent_id output; skipping teardown."
            exit 0
          fi
          if [ -z "${ADMIN_TOKEN:-}" ]; then
            echo "::warning::Missing admin token; cannot teardown deployed agent/capacity."
            exit 0
          fi
          dc="$(echo "${GCP_DC:-gcp:us-central1-a}" | tr '[:upper:]' '[:lower:]' | xargs)"
          echo "Teardown target: agent=$AGENT_ID datacenter=$dc node_size=llm"

          undeploy_code="$(curl -sS -o /tmp/undeploy.json -w "%{http_code}" \
            -X POST "$CP_URL/api/v1/agents/${AGENT_ID}/undeploy" \
            -H "Authorization: Bearer ${ADMIN_TOKEN}" \
            -H 'Accept: application/json' || true)"
          if [ "$undeploy_code" -lt 400 ]; then
            echo "Undeploy succeeded for agent ${AGENT_ID}."
          else
            echo "::warning::Undeploy failed (HTTP $undeploy_code): $(cat /tmp/undeploy.json)"
          fi

          cleanup_body="$(jq -cn --arg reason "ci:gcp-private-llm-post-test-teardown" '{dry_run:false, reason:$reason}')"
          cleanup_code="$(curl -sS -o /tmp/cleanup-agent.json -w "%{http_code}" \
            -X POST "$CP_URL/api/v1/admin/agents/${AGENT_ID}/cleanup" \
            -H "Authorization: Bearer ${ADMIN_TOKEN}" \
            -H 'Content-Type: application/json' \
            -d "$cleanup_body" || true)"
          if [ "$cleanup_code" -lt 400 ]; then
            echo "Agent cleanup succeeded for ${AGENT_ID}."
          else
            echo "::warning::Agent cleanup failed (HTTP $cleanup_code): $(cat /tmp/cleanup-agent.json)"
          fi

          target_code="$(curl -sS -o /tmp/cleanup-target.json -w "%{http_code}" \
            -X DELETE "$CP_URL/api/v1/admin/agents/capacity/targets?datacenter=${dc}&node_size=llm" \
            -H "Authorization: Bearer ${ADMIN_TOKEN}" \
            -H 'Accept: application/json' || true)"
          if [ "$target_code" -lt 400 ] || [ "$target_code" = "404" ]; then
            echo "Capacity target cleanup complete for ${dc}/llm (HTTP ${target_code})."
          else
            echo "::warning::Capacity target cleanup failed (HTTP $target_code): $(cat /tmp/cleanup-target.json)"
          fi

          agents_json="$(curl -sS -H "Authorization: Bearer ${ADMIN_TOKEN}" -H 'Accept: application/json' "$CP_URL/api/v1/agents" || true)"
          mapfile -t stale_ids < <(
            echo "$agents_json" | jq -r --arg dc "$dc" '
              [.agents[]?
                | select((.verified // false) == false)
                | select((.node_size // "" | ascii_downcase) == "llm")
                | select((.datacenter // "" | ascii_downcase) == $dc)
                | select((.vm_name // "") | startswith("ee-llm-"))
                | .agent_id] | unique[]?' 2>/dev/null || true
          )
          if [ "${#stale_ids[@]}" -gt 0 ]; then
            echo "Cleaning up ${#stale_ids[@]} unverified llm agent(s) in ${dc}..."
            for stale_id in "${stale_ids[@]}"; do
              curl -sS -X POST "$CP_URL/api/v1/admin/agents/${stale_id}/cleanup" \
                -H "Authorization: Bearer ${ADMIN_TOKEN}" \
                -H 'Content-Type: application/json' \
                -d "$cleanup_body" >/dev/null || true
            done
          else
            echo "No unverified ee-llm-* agents found in ${dc}."
          fi
