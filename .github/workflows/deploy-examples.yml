# Deploy Examples
#
# Deploys example apps after the CI workflow deploys the control plane.

name: Deploy Examples

on:
  workflow_run:
    workflows: [CI]
    types: [completed]
    branches: [main]
  workflow_dispatch:

jobs:
  test-unregistered-app-fails:
    name: Test - Unregistered app deploy fails
    runs-on: ubuntu-latest
    if: github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success'
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Deploy unregistered app (should fail)
        id: deploy
        uses: ./.github/actions/deploy
        continue-on-error: true
        with:
          app_name: unregistered-test-app
          compose_file: examples/hello-tdx/docker-compose.yml
          service_name: hello-tdx
          health_endpoint: /

      - name: Verify deploy failed
        run: |
          if [ "${{ steps.deploy.outcome }}" != "failure" ]; then
            echo "::error::Expected deploy to fail for unregistered app, but it succeeded"
            exit 1
          fi
          echo "Deploy correctly failed for unregistered app"

  deploy-hello-tdx:
    name: Deploy Hello TDX
    runs-on: ubuntu-latest
    needs: test-unregistered-app-fails
    if: github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success'
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Register app
        uses: ./.github/actions/register-app
        with:
          name: hello-tdx
          description: "Hello TDX - Example app demonstrating TDX attestation"

      - name: Deploy to EasyEnclave
        uses: ./.github/actions/deploy
        with:
          app_name: hello-tdx
          compose_file: examples/hello-tdx/docker-compose.yml
          service_name: hello-tdx
          health_endpoint: /

  deploy-private-llm:
    name: Deploy Private LLM
    runs-on: ubuntu-latest
    needs: deploy-hello-tdx
    if: github.event_name == 'workflow_dispatch' || github.event.workflow_run.conclusion == 'success'
    steps:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.event.workflow_run.head_sha || github.sha }}

      - name: Register app
        uses: ./.github/actions/register-app
        with:
          name: private-llm
          description: "Private LLM - Ollama running in a TDX enclave"

      - name: Deploy to EasyEnclave
        id: deploy
        uses: ./.github/actions/deploy
        with:
          app_name: private-llm
          compose_file: examples/private-llm/docker-compose.yml
          service_name: private-llm
          health_endpoint: /

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      - name: Install OpenAI SDK
        run: pip install openai

      - name: Test LLM query
        env:
          SERVICE_URL: ${{ steps.deploy.outputs.service_url }}
        run: |
          python3 << 'EOF'
          import os
          import time
          from openai import OpenAI

          service_url = os.environ["SERVICE_URL"]
          client = OpenAI(base_url=f"{service_url}/v1", api_key="unused")

          deadline = time.time() + 300  # 5 minutes
          while True:
              try:
                  response = client.chat.completions.create(
                      model="smollm2:135m",
                      messages=[{"role": "user", "content": "Say hello in one sentence."}],
                  )
                  break
              except Exception as e:
                  if time.time() >= deadline:
                      raise RuntimeError(f"LLM not ready after 5 minutes: {e}") from e
                  print(f"Model not ready yet ({e}), retrying in 15s...")
                  time.sleep(15)

          content = response.choices[0].message.content
          assert content, "Response content is empty"
          print(f"LLM response: {content}")
          EOF
