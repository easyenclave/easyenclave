# Private LLM with E2E Encryption via Noise Protocol
#
# This compose file runs:
# 1. Ollama - Local LLM server
# 2. Proxy - FastAPI with Noise Protocol E2E encryption
#
# IMPORTANT: Deploy in a TDX Trust Domain for full security.
# Requires /sys/kernel/config/tsm/report for attestation.

services:
  ollama:
    image: ollama/ollama:latest
    volumes:
      - ollama_data:/root/.ollama
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:11434/"]
      interval: 10s
      timeout: 5s
      retries: 5

  proxy:
    build:
      context: ./app
    ports:
      - "8080:8080"
    environment:
      - OLLAMA_HOST=http://ollama:11434
      - MODEL_NAME=qwen2.5:0.5b
      # Intel API key can be set here or in /share/config.json
      # - INTEL_API_KEY=${INTEL_API_KEY}
    volumes:
      # Mount share directory for config (Intel API key)
      - /share:/share:ro
      # TDX report interface (required for attestation)
      - /sys/kernel/config/tsm/report:/sys/kernel/config/tsm/report
    depends_on:
      ollama:
        condition: service_healthy

volumes:
  ollama_data:
